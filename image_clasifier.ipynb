{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c29e046-0018-4c24-b81c-9cccc7b0144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# -----------------------------\n",
    "# 1. PARAMETERS\n",
    "# -----------------------------\n",
    "\n",
    "image_size = (64,64) # Resizes all the loaded images into a size of 64X64 pixels \n",
    "data_directory = \"Images\" # Specifies the root directory containing the image sub-folders (ie. \"Dogs\" and \"Cats\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. LOAD IMAGES\n",
    "# -----------------------------\n",
    "def loading_images(data_directory,mode, image_size):\n",
    "\n",
    "    \"\"\"\n",
    "    Loads images from the specified directory, resizes them, flattens them into vectors,\n",
    "    and assigns labels based on folder names.\n",
    "\n",
    "    Assumes each class has a subfolder with 'train' images.\n",
    "\n",
    "    Arguments:\n",
    "    data_directory -- string, path to the root directory containing class folders\n",
    "    mode -- string, either 'train' or 'test' to specify which subfolder to load\n",
    "    image_size -- tuple(int, int), size to which each image will be resized (width, height)\n",
    "\n",
    "    Returns:\n",
    "    X -- list of numpy arrays, each array is a flattened image vector\n",
    "    y -- list of integers, labels corresponding to each image\n",
    "    label_dict-- dictionary mapping class names (folder names) to integer labels, e.g., {'Dogs': 0, 'Cats': 1}\n",
    "    \"\"\"\n",
    "    X = [] # Empty list for storing flattened image vectors \n",
    "    y = [] # Empty list for storing interger labels (0 and 1)\n",
    "    \n",
    "    # Get class labels from folder names and map to integers\n",
    "    \n",
    "    labels = os.listdir(data_directory) # lists all the sub-folders of the specified root directory, that contain the images\n",
    "    label_dict = {label: i for i, label in enumerate(labels)}\n",
    "    \n",
    "    # Loop through each class folder and creates path for the mode\n",
    "    for label in labels:\n",
    "        folder = os.path.join(data_directory, label, mode)\n",
    "        if not os.path.isdir(folder):\n",
    "            continue  # Skip if train/test folder doesn't exist\n",
    "\n",
    "        Files = os.listdir(folder)\n",
    "        for filename in Files:\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder, filename)\n",
    "               # Open image and convert to RGB\n",
    "                img = Image.open(image_path).convert(\"RGB\")\n",
    "              # Resizes the loaded image into the size specified above (64x64 pixels)\n",
    "                img_resized = img.resize(image_size)\n",
    "              # Creates a numpy array from the resized image\n",
    "                X_array = np.array(img_resized)\n",
    "             # Flattens the array into a vector and appends it into X\n",
    "                X.append(X_array.flatten())\n",
    "             # Appends each class label into a list \"y\"\n",
    "                y.append(label_dict[label])\n",
    "\n",
    "    # Converts X into an array and normalizes all pixel values to [0,1]\n",
    "    X_norm = (np.array(X))/255.0\n",
    "    # Converts y labels into an array\n",
    "    y_array = np.array(y)\n",
    "    \n",
    "    return X_norm, y_array, label_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a20572-6050-48b2-b672-c479843944e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assigning the outputs of the \"loading_images\" function to their respective variables\n",
    "X_train, y_train, label_dict = loading_images(\"../Images\", \"train\", image_size)\n",
    "X_test, y_test = loading_images(\"../Images\", \"test\", image_size)[:2]\n",
    "\n",
    "# Transpose for math: changing dimensions to (features, training_examples)\n",
    "X_train, X_test = X_train.T, X_test.T\n",
    "y_train, y_test = y_train.reshape(1, y_train.shape[0]), y_test.reshape(1, y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cc56e2e2-6258-43de-b42c-f321e0a60ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------\n",
    "# 3. PARAMETER INITIALIZATION FUNCTION\n",
    "# ------------------------------------\n",
    "\n",
    "def parameter_init(input_size, hidden_1, hidden_2, hidden_3, output_size):\n",
    "    \"\"\"Initializes weights and biases for a 4-layer neural network.\n",
    "    \n",
    "    Arguments:    \n",
    "    input_size -- int, number of input features (size of the input layer)\n",
    "    hidden_1 -- int, number of units in the first hidden layer\n",
    "    hidden_2 -- int, number of units in the second hidden layer\n",
    "    hidden_3 -- int, number of units in the third hidden layer\n",
    "    output_size -- int, number of units in the output layer\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- dict containing initialized weights (W1, W2, W3, W4) \n",
    "                  and biases (b1, b2, b3, b4) for each layer\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # Weights: initialized with small random values (scaled by 0.01)\n",
    "    # to prevent exploding activations and help stable learning.\n",
    "    # Biases: initialized to zero.\n",
    "    W1 = np.random.randn(hidden_1, input_size)*np.sqrt(2. / input_size)\n",
    "    b1 = np.zeros((hidden_1, 1))\n",
    "    W2 = np.random.randn(hidden_2, hidden_1)* np.sqrt(2. / hidden_1)\n",
    "    b2 = np.zeros((hidden_2,1))\n",
    "    W3 = np.random.randn(hidden_3, hidden_2)* np.sqrt(2. / hidden_2)\n",
    "    b3 = np.zeros((hidden_3,1))\n",
    "    W4 = np.random.randn(output_size, hidden_3)* np.sqrt(2. / hidden_3)\n",
    "    b4 = np.zeros((output_size,1))\n",
    "    parameters = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2, \"W3\":W3, \"b3\":b3, \"W4\":W4, \"b4\":b4}\n",
    "    return parameters\n",
    "    \n",
    "\n",
    "# -----------------------------\n",
    "# 4. ACTIVATION FUNCTIONS\n",
    "# -----------------------------\n",
    "\n",
    "def relu(Z):\n",
    "    A = np.maximum(0,Z)\n",
    "    return A\n",
    "def relu_derivative(Z):\n",
    "    return (Z>0).astype(float)\n",
    "def sigmoid(Z4):\n",
    "    y_hat = 1/(1 + np.exp(-Z4))\n",
    "    return y_hat\n",
    "\n",
    "def sigmoid_derivative(y_hat):\n",
    "    y_hat_derivative = y_hat*(1-y_hat)\n",
    "    return y_hat_derivative\n",
    "\n",
    "# -------------------------------\n",
    "# 5. FORWARD BACKWARD PROPAGATION\n",
    "# -------------------------------\n",
    "\n",
    "# Before calling this function, make sure to initialize parameters:\n",
    "# parameters = parameter_init(input_size, hidden_1, hidden_2, hidden_3, output_size)\n",
    "def forward_prop(X_train, parameters):\n",
    "\n",
    "    # Retrieve weights and biases from dictionary\n",
    "    W1, b1 = parameters[\"W1\"], parameters[\"b1\"]\n",
    "    W2, b2 = parameters[\"W2\"], parameters[\"b2\"]\n",
    "    W3, b3 = parameters[\"W3\"], parameters[\"b3\"]\n",
    "    W4, b4 = parameters[\"W4\"], parameters[\"b4\"]\n",
    "\n",
    "    Z1 = W1.dot(X_train) + b1\n",
    "    A1 = relu(Z1)  \n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = relu(Z2)\n",
    "    Z3 = W3.dot(A2) + b3\n",
    "    A3 = relu(Z3)\n",
    "    Z4 = W4.dot(A3) + b4\n",
    "    y_hat = sigmoid (Z4)\n",
    "\n",
    "    cache = {\"Z1\":Z1, \"A1\": A1, \"Z2\": Z2, \"A2\": A2, \"Z3\": Z3,\"A3\": A3,\"Z4\": Z4, \"A4\": y_hat}\n",
    "    return cache\n",
    "\n",
    "def Cost_function(y, y_hat):\n",
    "    m = y.shape[1] # number of training examples\n",
    "    cost = -np.sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat)) / m\n",
    "    cost = np.squeeze(cost) \n",
    "    return cost\n",
    "    \n",
    "# -------------------------------\n",
    "# 5. BACKWARD BACKWARD PROPAGATION\n",
    "# -------------------------------\n",
    "\n",
    "def backward_prob(parameters, cache, X_train, y_train):\n",
    "    W1, W2, W3, W4 = parameters[\"W1\"], parameters[\"W2\"], parameters[\"W3\"], parameters[\"W4\"]\n",
    "    A1, A2, A3, A4 = cache[\"A1\"], cache[\"A2\"], cache[\"A3\"], cache[\"A4\"]\n",
    "    Z1, Z2, Z3, Z4 = cache[\"Z1\"], cache[\"Z2\"], cache[\"Z3\"], cache[\"Z4\"]\n",
    "    \n",
    "    m = X_train.shape[1]\n",
    "\n",
    "    # Layer 4 (output layer)\n",
    "    dZ4 = A4 - y_train\n",
    "    dW4 = (1/m) * np.dot(dZ4, A3.T)\n",
    "    db4 = (1/m) * np.sum(dZ4, axis=1, keepdims=True)\n",
    "\n",
    "    # Hidden Layer 3\n",
    "    dZ3 = np.dot(W4.T, dZ4) * relu_derivative(Z3)\n",
    "    dW3 = (1/m) * np.dot(dZ3, A2.T)\n",
    "    db3 = (1/m) * np.sum(dZ3, axis=1, keepdims=True)\n",
    "\n",
    "    # Hidden Layer 2\n",
    "    dZ2 = np.dot(W3.T, dZ3) * relu_derivative(Z2)\n",
    "    dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    # Hidden Layer 1\n",
    "    dZ1 = np.dot(W2.T, dZ2) * relu_derivative(Z1)\n",
    "    dW1 = (1/m) * np.dot(dZ1, X_train.T)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    derivatives = {\n",
    "        \"dW4\": dW4, \"db4\": db4,\n",
    "        \"dW3\": dW3, \"db3\": db3,\n",
    "        \"dW2\": dW2, \"db2\": db2,\n",
    "        \"dW1\": dW1, \"db1\": db1\n",
    "    }\n",
    "    \n",
    "    return derivatives\n",
    "\n",
    "def parameter_update(parameters, derivatives, learning_rate = 1.2):\n",
    "\n",
    "    L = len(parameters) // 2  # number of layers\n",
    "    for l in range(1, L + 1):\n",
    "        print(f\"Layer {l}: mean|dW| = {np.mean(np.abs(derivatives[f'dW{l}'])):.6f}, \"\n",
    "          f\"mean|db| = {np.mean(np.abs(derivatives[f'db{l}'])):.6f}\")\n",
    "        parameters[f\"W{l}\"] -= learning_rate * derivatives[f\"dW{l}\"]\n",
    "        parameters[f\"b{l}\"] -= learning_rate * derivatives[f\"db{l}\"]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4eac8be1-d9cc-497a-9b5f-1325a3bc5366",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters=parameter_init(12288,128,64,32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "41a447f3-2367-4ed2-b6e2-cfed43b58d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7ad913d4-39e4-4da6-bf40-c9c6f04b39f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: mean|dW| = 0.003552, mean|db| = 0.006000\n",
      "Layer 2: mean|dW| = 0.003115, mean|db| = 0.007532\n",
      "Layer 3: mean|dW| = 0.003795, mean|db| = 0.011754\n",
      "Layer 4: mean|dW| = 0.038013, mean|db| = 0.119673\n",
      "Max change in W1: 0.03983302231755669\n"
     ]
    }
   ],
   "source": [
    "W2_before = parameters[\"W2\"].copy()\n",
    "parameters = parameter_update(parameters, derivatives, learning_rate=1.2)\n",
    "W1_after = parameters[\"W2\"]\n",
    "\n",
    "print(\"Max change in W1:\", np.max(np.abs(W1_after - W1_before)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "783c864e-b697-4fe1-a8b2-1e77997379e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = forward_prop(X_train, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ea4d31d8-13ea-45a2-9828-c617aa9b65e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: mean|dW| = 0.003552, mean|db| = 0.006000\n",
      "Layer 2: mean|dW| = 0.003115, mean|db| = 0.007532\n",
      "Layer 3: mean|dW| = 0.003795, mean|db| = 0.011754\n",
      "Layer 4: mean|dW| = 0.038013, mean|db| = 0.119673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.02889013,  0.00053516,  0.00181529, ...,  0.00063127,\n",
       "          0.00248862,  0.01869865],\n",
       "        [ 0.01479205,  0.00482789, -0.00656446, ...,  0.01124901,\n",
       "         -0.00381177,  0.00496795],\n",
       "        [-0.00776768, -0.00560723,  0.00523111, ...,  0.00898555,\n",
       "         -0.00232056, -0.00973639],\n",
       "        ...,\n",
       "        [-0.01919107,  0.0044938 ,  0.00145654, ..., -0.00715212,\n",
       "         -0.01475998, -0.01429131],\n",
       "        [ 0.02341782,  0.00506834,  0.01722273, ..., -0.00477758,\n",
       "         -0.00085054, -0.00276448],\n",
       "        [ 0.00686845,  0.00876229,  0.00233785, ..., -0.01925701,\n",
       "          0.03737518,  0.02437289]]),\n",
       " 'b1': array([[ 1.15978291e-02],\n",
       "        [ 3.26759120e-03],\n",
       "        [-4.12537040e-03],\n",
       "        [-2.32972815e-04],\n",
       "        [-2.27449749e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [-2.43642136e-03],\n",
       "        [ 3.72203567e-03],\n",
       "        [-1.00932519e-04],\n",
       "        [-1.41577517e-03],\n",
       "        [ 6.28614079e-03],\n",
       "        [-2.14263787e-03],\n",
       "        [ 5.27358172e-03],\n",
       "        [-1.19686877e-03],\n",
       "        [-3.82718244e-03],\n",
       "        [ 4.12548812e-03],\n",
       "        [-3.59782818e-03],\n",
       "        [-1.71243439e-04],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 3.17746683e-03],\n",
       "        [ 2.42181060e-03],\n",
       "        [-2.16203066e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 4.83165856e-04],\n",
       "        [-6.27841059e-03],\n",
       "        [-2.36356639e-03],\n",
       "        [-3.47002394e-03],\n",
       "        [ 1.06759471e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [-3.53479096e-03],\n",
       "        [-6.49980883e-03],\n",
       "        [ 3.58969095e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 1.13683729e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [-8.43908101e-04],\n",
       "        [ 4.81069085e-04],\n",
       "        [ 1.32398692e-03],\n",
       "        [ 1.76023925e-03],\n",
       "        [-3.27021346e-03],\n",
       "        [ 1.24783306e-03],\n",
       "        [ 2.75744796e-03],\n",
       "        [ 1.75665881e-03],\n",
       "        [-4.88606828e-03],\n",
       "        [ 2.42900394e-03],\n",
       "        [ 3.36401579e-04],\n",
       "        [-5.25691391e-03],\n",
       "        [ 3.87502684e-04],\n",
       "        [-3.03315057e-04],\n",
       "        [ 4.24807285e-03],\n",
       "        [-1.78413510e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 3.87536803e-04],\n",
       "        [-3.07561464e-03],\n",
       "        [-1.09609966e-02],\n",
       "        [-2.91632402e-03],\n",
       "        [ 3.71278028e-03],\n",
       "        [ 5.21813402e-03],\n",
       "        [ 1.29269220e-02],\n",
       "        [ 5.14438261e-03],\n",
       "        [-2.34370833e-03],\n",
       "        [-1.12252126e-02],\n",
       "        [-1.38229510e-02],\n",
       "        [ 3.22654589e-03],\n",
       "        [-6.37874895e-05],\n",
       "        [ 7.41172627e-04],\n",
       "        [ 0.00000000e+00],\n",
       "        [-2.90641911e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [-4.68836918e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [-4.29625855e-03],\n",
       "        [-5.42998853e-03],\n",
       "        [ 3.80736008e-05],\n",
       "        [ 0.00000000e+00],\n",
       "        [-6.78405268e-04],\n",
       "        [ 2.31807600e-03],\n",
       "        [ 4.45132110e-03],\n",
       "        [-1.21648306e-02],\n",
       "        [-5.34844726e-03],\n",
       "        [-6.07003573e-03],\n",
       "        [ 3.98316428e-03],\n",
       "        [ 5.52226947e-03],\n",
       "        [ 2.13112571e-03],\n",
       "        [ 3.19000552e-03],\n",
       "        [-8.40027599e-03],\n",
       "        [-1.04028358e-03],\n",
       "        [ 1.23614616e-03],\n",
       "        [-6.31966862e-03],\n",
       "        [-6.09538267e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 2.51902981e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [-5.00325676e-03],\n",
       "        [-1.02562784e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [-5.02955682e-03],\n",
       "        [ 3.40183969e-03],\n",
       "        [ 3.50389219e-03],\n",
       "        [ 2.63229809e-03],\n",
       "        [ 6.85674531e-03],\n",
       "        [-1.60545360e-03],\n",
       "        [-2.25476258e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 7.61741780e-03],\n",
       "        [-7.00511710e-04],\n",
       "        [-3.79246377e-03],\n",
       "        [ 4.96609599e-03],\n",
       "        [-2.56556351e-03],\n",
       "        [-8.15104456e-03],\n",
       "        [ 3.56565505e-04],\n",
       "        [ 4.48527900e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 1.07305036e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 1.15979575e-03],\n",
       "        [ 1.18724850e-02],\n",
       "        [-2.04335814e-03],\n",
       "        [ 5.32987935e-03],\n",
       "        [-7.20002408e-05],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 2.94838937e-03],\n",
       "        [-3.81141335e-03],\n",
       "        [-7.49362088e-04],\n",
       "        [ 1.34381021e-03]]),\n",
       " 'W2': array([[ 0.13565877, -0.02381807,  0.1070118 , ...,  0.00813392,\n",
       "          0.04163124,  0.06461526],\n",
       "        [-0.10584398, -0.01409591, -0.07047064, ..., -0.05090847,\n",
       "          0.05559263, -0.02507851],\n",
       "        [-0.03726581,  0.0592674 ,  0.03477242, ...,  0.00624726,\n",
       "          0.5028688 ,  0.06674959],\n",
       "        ...,\n",
       "        [-0.18464729, -0.10794113, -0.17434375, ..., -0.04274566,\n",
       "          0.16070535, -0.01881277],\n",
       "        [-0.01896992,  0.18545056,  0.14811681, ...,  0.17136502,\n",
       "         -0.11902191, -0.0085161 ],\n",
       "        [ 0.08379459,  0.0329156 , -0.18656858, ..., -0.13628303,\n",
       "          0.17653276,  0.03138259]]),\n",
       " 'b2': array([[ 0.00391636],\n",
       "        [-0.00027966],\n",
       "        [-0.00179171],\n",
       "        [-0.00015235],\n",
       "        [-0.00036471],\n",
       "        [ 0.0004268 ],\n",
       "        [ 0.00058714],\n",
       "        [-0.00110964],\n",
       "        [-0.00160483],\n",
       "        [ 0.        ],\n",
       "        [ 0.00075672],\n",
       "        [-0.01092958],\n",
       "        [ 0.00460231],\n",
       "        [-0.00294816],\n",
       "        [-0.00225767],\n",
       "        [-0.00247433],\n",
       "        [ 0.01452579],\n",
       "        [-0.00236619],\n",
       "        [-0.01735862],\n",
       "        [-0.00283257],\n",
       "        [-0.00041628],\n",
       "        [-0.00107586],\n",
       "        [ 0.01280676],\n",
       "        [ 0.00613377],\n",
       "        [-0.00423437],\n",
       "        [ 0.        ],\n",
       "        [ 0.00143856],\n",
       "        [-0.00393841],\n",
       "        [ 0.00019943],\n",
       "        [ 0.00077912],\n",
       "        [-0.00524292],\n",
       "        [-0.00388348],\n",
       "        [ 0.00534151],\n",
       "        [ 0.00083865],\n",
       "        [-0.00563309],\n",
       "        [-0.00263338],\n",
       "        [-0.00152424],\n",
       "        [-0.00145221],\n",
       "        [ 0.00538847],\n",
       "        [-0.00366716],\n",
       "        [-0.00601689],\n",
       "        [ 0.        ],\n",
       "        [-0.00592317],\n",
       "        [-0.00727741],\n",
       "        [ 0.00576847],\n",
       "        [ 0.0015045 ],\n",
       "        [ 0.00024064],\n",
       "        [ 0.00434968],\n",
       "        [ 0.00360554],\n",
       "        [-0.00804356],\n",
       "        [-0.00078825],\n",
       "        [ 0.        ],\n",
       "        [ 0.00026865],\n",
       "        [-0.00566811],\n",
       "        [-0.00192847],\n",
       "        [-0.01038377],\n",
       "        [-0.0005867 ],\n",
       "        [-0.00683366],\n",
       "        [ 0.        ],\n",
       "        [-0.00342113],\n",
       "        [ 0.        ],\n",
       "        [-0.01737603],\n",
       "        [-0.00514272],\n",
       "        [-0.00797276]]),\n",
       " 'W3': array([[-0.21230715, -0.27515354,  0.1903619 , ..., -0.00704079,\n",
       "          0.04156784, -0.20683615],\n",
       "        [-0.06348064,  0.0758346 ,  0.13287484, ...,  0.12528953,\n",
       "          0.22595827,  0.28283859],\n",
       "        [-0.04751228,  0.02795379, -0.05817243, ...,  0.22937157,\n",
       "         -0.03103265, -0.07855657],\n",
       "        ...,\n",
       "        [ 0.13433806,  0.27527331,  0.08082291, ..., -0.20222934,\n",
       "          0.04676106, -0.18373612],\n",
       "        [-0.1897734 , -0.14313179,  0.36299279, ..., -0.07314589,\n",
       "         -0.06627773, -0.0057517 ],\n",
       "        [-0.02348816,  0.08098757, -0.14035096, ..., -0.10986068,\n",
       "         -0.20666102,  0.06457312]]),\n",
       " 'b3': array([[ 0.        ],\n",
       "        [ 0.00849382],\n",
       "        [-0.00642728],\n",
       "        [ 0.01322928],\n",
       "        [ 0.0005679 ],\n",
       "        [ 0.        ],\n",
       "        [ 0.00058364],\n",
       "        [ 0.00864011],\n",
       "        [-0.00167099],\n",
       "        [ 0.01118097],\n",
       "        [ 0.00060749],\n",
       "        [-0.00291754],\n",
       "        [ 0.        ],\n",
       "        [-0.01114517],\n",
       "        [-0.00133063],\n",
       "        [ 0.00123336],\n",
       "        [ 0.00367395],\n",
       "        [-0.00103512],\n",
       "        [ 0.00458107],\n",
       "        [-0.01552421],\n",
       "        [-0.02087327],\n",
       "        [-0.00155355],\n",
       "        [ 0.02903214],\n",
       "        [ 0.00240621],\n",
       "        [ 0.00458893],\n",
       "        [ 0.00804806],\n",
       "        [-0.00395407],\n",
       "        [-0.01406007],\n",
       "        [-0.00216761],\n",
       "        [-0.00579321],\n",
       "        [-0.00249611],\n",
       "        [-0.00024849]]),\n",
       " 'W4': array([[ 0.1883388 , -0.22478186,  0.41048832, -0.25442539, -0.04712882,\n",
       "         -0.08764299,  0.06774511,  0.51231071,  0.01874896, -0.19800114,\n",
       "         -0.04137068,  0.35508788, -0.13849397,  0.27258175,  0.02769375,\n",
       "         -0.05578214, -0.09016065,  0.08497296, -0.22307671,  0.21889146,\n",
       "          0.30516948, -0.20462855, -0.40417721,  0.23313523, -0.29346448,\n",
       "         -0.15819222,  0.12716021,  0.09859128, -0.01255392,  0.43364062,\n",
       "          0.09771983,  0.01359892]]),\n",
       " 'b4': array([[-0.05983634]])}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derivatives = backward_prob(parameters, cache, X_train, y_train )\n",
    "parameter_update(parameters, derivatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58961735-968a-483b-9a80-e94079b7a1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9696ba-5e8f-4f92-b3d3-408e13c21b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_prob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac497cb7-ec3c-4e92-a757-6753c487462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters=parameter_init(12288,128,64,32,1)\n",
    "y_hat = forward_prop(X_train, parameters)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b827f7-4471-4ca0-bd19-b1a3e5177036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931441807084028"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cost_function(y_train, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dd714c2-928f-4484-952c-54372ffa3afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50002217, 0.50000296, 0.5000125 , 0.50001995, 0.50002182,\n",
       "        0.50001195, 0.50000897, 0.50000907, 0.50001882, 0.50003302,\n",
       "        0.50003582, 0.50001238, 0.50002145, 0.500018  , 0.50000161,\n",
       "        0.50000136, 0.50002337, 0.50002958, 0.5000227 , 0.50002496]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "364d74e3-e696-47f5-a041-e55bcb4aae43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32096b65-b4f4-46a8-a4f6-d13713daf50d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
