{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c29e046-0018-4c24-b81c-9cccc7b0144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# -----------------------------\n",
    "# 1. PARAMETERS\n",
    "# -----------------------------\n",
    "\n",
    "image_size = (64,64) # Resizes all the loaded images into a size of 64X64 pixels \n",
    "data_directory = \"Images\" # Specifies the root directory containing the image sub-folders (ie. \"Dogs\" and \"Cats\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. LOAD IMAGES\n",
    "# -----------------------------\n",
    "def loading_images(data_directory,mode, image_size):\n",
    "\n",
    "    \"\"\"\n",
    "    Loads images from the specified directory, resizes them, flattens them into vectors,\n",
    "    and assigns labels based on folder names.\n",
    "\n",
    "    Assumes each class has a subfolder with 'train' images.\n",
    "\n",
    "    Arguments:\n",
    "    data_directory -- string, path to the root directory containing class folders\n",
    "    mode -- string, either 'train' or 'test' to specify which subfolder to load\n",
    "    image_size -- tuple(int, int), size to which each image will be resized (width, height)\n",
    "\n",
    "    Returns:\n",
    "    X -- list of numpy arrays, each array is a flattened image vector\n",
    "    y -- list of integers, labels corresponding to each image\n",
    "    label_dict-- dictionary mapping class names (folder names) to integer labels, e.g., {'Dogs': 0, 'Cats': 1}\n",
    "    \"\"\"\n",
    "    X = [] # Empty list for storing flattened image vectors \n",
    "    y = [] # Empty list for storing interger labels (0 and 1)\n",
    "    \n",
    "    # Get class labels from folder names and map to integers\n",
    "    \n",
    "    labels = os.listdir(data_directory) # lists all the sub-folders of the specified root directory, that contain the images\n",
    "    label_dict = {label: i for i, label in enumerate(labels)}\n",
    "    \n",
    "    # Loop through each class folder and creates path for the mode\n",
    "    for label in labels:\n",
    "        folder = os.path.join(data_directory, label, mode)\n",
    "        if not os.path.isdir(folder):\n",
    "            continue  # Skip if train/test folder doesn't exist\n",
    "\n",
    "        Files = os.listdir(folder)\n",
    "        for filename in Files:\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder, filename)\n",
    "               # Open image and convert to RGB\n",
    "                img = Image.open(image_path).convert(\"RGB\")\n",
    "              # Resizes the loaded image into the size specified above (64x64 pixels)\n",
    "                img_resized = img.resize(image_size)\n",
    "              # Creates a numpy array from the resized image\n",
    "                X_array = np.array(img_resized)\n",
    "             # Flattens the array into a vector and appends it into X\n",
    "                X.append(X_array.flatten())\n",
    "             # Appends each class label into a list \"y\"\n",
    "                y.append(label_dict[label])\n",
    "\n",
    "    # Converts X into an array and normalizes all pixel values to [0,1]\n",
    "    X_norm = (np.array(X))/255.0\n",
    "    # Converts y labels into an array\n",
    "    y_array = np.array(y)\n",
    "    \n",
    "    return X_norm, y_array, label_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a20572-6050-48b2-b672-c479843944e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assigning the outputs of the \"loading_images\" function to their respective variables\n",
    "X_train, y_train, label_dict = loading_images(\"../Images\", \"train\", image_size)\n",
    "X_test, y_test = loading_images(\"../Images\", \"test\", image_size)[:2]\n",
    "\n",
    "# Transpose for math: changing dimensions to (features, training_examples)\n",
    "X_train, X_test = X_train.T, X_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc56e2e2-6258-43de-b42c-f321e0a60ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3. HELPER FUNCTIONS\n",
    "# -----------------------------\n",
    "\n",
    "def parameter_init(input_size, hidden_1, hidden_2, hidden_3, output_size):\n",
    "    \"\"\"Initializes weights and biases for a 4-layer neural network.\n",
    "    \n",
    "    Arguments:    \n",
    "    input_size -- int, number of input features (size of the input layer)\n",
    "    hidden_1 -- int, number of units in the first hidden layer\n",
    "    hidden_2 -- int, number of units in the second hidden layer\n",
    "    hidden_3 -- int, number of units in the third hidden layer\n",
    "    output_size -- int, number of units in the output layer\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- dict containing initialized weights (W1, W2, W3, W4) \n",
    "                  and biases (b1, b2, b3, b4) for each layer\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # Weights: initialized with small random values (scaled by 0.01)\n",
    "    # to prevent exploding activations and help stable learning.\n",
    "    # Biases: initialized to zero.\n",
    "    W1 = np.random.randn(hidden_1, input_size)*0.01\n",
    "    b1 = np.zeros((hidden_1, 1))\n",
    "    W2 = np.random.randn(hidden_2, hidden_1)*0.01\n",
    "    b2 = np.zeros((hidden_2,1))\n",
    "    W3 = np.random.randn(hidden_3, hidden_2)*0.01\n",
    "    b3 = np.zeros((hidden_3,1))\n",
    "    W4 = np.random.randn(output_size, hidden_3)*0.01\n",
    "    b4 = np.zeros((output_size,1))\n",
    "    parameters = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2, \"W3\":W3, \"b3\":b3, \"W4\":W4, \"b4\":b4}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "006f5f82-b6a0-4504-8942-986efd3841fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.01624345, -0.00611756, -0.00528172, -0.01072969,  0.00865408,\n",
       "         -0.02301539,  0.01744812, -0.00761207,  0.00319039, -0.0024937 ],\n",
       "        [ 0.01462108, -0.02060141, -0.00322417, -0.00384054,  0.01133769,\n",
       "         -0.01099891, -0.00172428, -0.00877858,  0.00042214,  0.00582815],\n",
       "        [-0.01100619,  0.01144724,  0.00901591,  0.00502494,  0.00900856,\n",
       "         -0.00683728, -0.0012289 , -0.00935769, -0.00267888,  0.00530355],\n",
       "        [-0.00691661, -0.00396754, -0.00687173, -0.00845206, -0.00671246,\n",
       "         -0.00012665, -0.0111731 ,  0.00234416,  0.01659802,  0.00742044],\n",
       "        [-0.00191836, -0.00887629, -0.00747158,  0.01692455,  0.00050808,\n",
       "         -0.00636996,  0.00190915,  0.02100255,  0.00120159,  0.00617203]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[ 0.0030017 , -0.0035225 , -0.01142518, -0.00349343, -0.00208894],\n",
       "        [ 0.00586623,  0.00838983,  0.00931102,  0.00285587,  0.00885141],\n",
       "        [-0.00754398,  0.01252868,  0.0051293 , -0.00298093,  0.00488518],\n",
       "        [-0.00075572,  0.01131629,  0.01519817,  0.02185575, -0.01396496],\n",
       "        [-0.01444114, -0.00504466,  0.00160037,  0.00876169,  0.00315635],\n",
       "        [-0.02022201, -0.00306204,  0.00827975,  0.00230095,  0.00762011],\n",
       "        [-0.00222328, -0.00200758,  0.00186561,  0.00410052,  0.001983  ],\n",
       "        [ 0.00119009, -0.00670662,  0.00377564,  0.00121821,  0.01129484]]),\n",
       " 'b2': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W3': array([[ 0.01198918,  0.00185156, -0.00375285, -0.0063873 ,  0.00423494,\n",
       "          0.0007734 , -0.00343854,  0.00043597],\n",
       "        [-0.00620001,  0.00698032, -0.00447129,  0.01224508,  0.00403492,\n",
       "          0.00593579, -0.01094912,  0.00169382],\n",
       "        [ 0.00740556, -0.00953701, -0.00266219,  0.00032615, -0.01373117,\n",
       "          0.00315159,  0.00846161, -0.00859516],\n",
       "        [ 0.00350546, -0.01312283, -0.00038696, -0.01615772,  0.01121418,\n",
       "          0.00408901, -0.00024617, -0.00775162]]),\n",
       " 'b3': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W4': array([[ 0.01273756,  0.01967102, -0.01857982,  0.01236164]]),\n",
       " 'b4': array([[0.]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_init(12288,128,64,32 â†’ 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d9cdf-d3e3-4215-bdaa-fd10d64e4c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
